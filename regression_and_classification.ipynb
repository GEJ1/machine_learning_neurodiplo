{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GEJ1/machine_learning_neurodiplo/blob/main/regression_and_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning resources\n",
        "\n",
        "Author: Daniel Low (https://github.com/danielmlow)\n",
        "\n",
        "Adapted from: https://github.com/danielmlow/tutorials/blob/main/machine_learning/regression_and_classification.ipynb"
      ],
      "metadata": {
        "id": "nbKGXxWFyFAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "courses:\n",
        "- http://materias.df.uba.ar/lda2021c1/171-2/\n",
        "- https://www.kaggle.com/thirty-days-of-ml-assignments\n",
        "- https://sebastianraschka.com/blog/2021/ml-course.html\n",
        "- Coursera\n",
        "\n",
        "Tutorials\n",
        "- https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
        "- Feature importance: https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
        "\n",
        "Books:\n",
        "- introductory book: Deuschle, WJ (2019). Undergraduate Fundamentals of Machine Learning link here. It's like a basic version of Murphy (see below)\n",
        "- Advanced: Murphy, K. P. (2022). Machine learning: a probabilistic perspective. link\n",
        "James et al (2021). An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics)\n",
        "\n",
        "Other\n",
        "- Deep dive into evaluation metrics of performance and related analyses:  Varoquaux, G., & Colliot, O. (2022). Evaluating machine learning models and their diagnostic value.\n",
        "- More resources (statistics, NLP): https://docs.google.com/document/d/127Npk6Z2gV-p_ewwnRz7qDyvKKRI6vb6Yg3zKnOw16s/edit?usp=sharing\n",
        "- Machine learning without programming: https://jasp-stats.org/\n",
        "\n"
      ],
      "metadata": {
        "id": "5t-s5ULjyH44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning tutorial\n",
        "\n",
        "Data from: Torrente, F., Yoris, A., Low, D., Lopez, P., Bekinschtein, P., Vázquez, G. H., ... & Cetkovich, M. (2022). Psychological symptoms, mental fatigue and behavioural adherence after 72 continuous days of strict lockdown during the COVID-19 pandemic in Argentina. BJPsych open, 8(1).\n",
        "\n",
        "Data were collected between 21 May 2020 and 4 June 2020 (early pandemic). The survey reached 3617 adults (85.2% female) from all provinces of Argentina after 72 days of lockdown. In that period, Argentina had an Oxford stringency index of 85/100. Of those surveyed, 45.6% met the cut-offs for depression (10 or higher), that is, PHQ-9  levels were much higher than at the start of the pandemic (33.7% [Torrente et al. (2021). J Affect Disord]) and pre-pandemic (5.6%; [Daray et al. (2017). J Affect Disord]) in Argentine samples.\n",
        "\n",
        "Here we can try to predict a participant's depression score (either ordinal or binary) from their other mental health and demographic data."
      ],
      "metadata": {
        "id": "H3du-trbNnZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
      ],
      "metadata": {
        "id": "HvbGPvhEKlQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBdkco_ocfjN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LassoCV, Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQnVP6YeNi_o"
      },
      "outputs": [],
      "source": [
        "# setting to see all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# figure size in inches\n",
        "rcParams['figure.figsize'] = 5,5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data and set input/output paths"
      ],
      "metadata": {
        "id": "WHsx1I9AS3Nh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFurJeyGNi_o"
      },
      "outputs": [],
      "source": [
        "load_from_google_drive = False\n",
        "# config: depends whether you're on Google Colab or local\n",
        "\n",
        "# Get URL from github csv by clicking on Download > Copy Link Address\n",
        "# https://github.com/danielmlow/covid19_argentina/blob/main/data/input/Emotional%20symptoms%20COVID19_Arg_May20_v2_text.csv\n",
        "df = pd.read_csv('https://github.com/danielmlow/covid19_argentina/raw/main/data/input/Emotional%20symptoms%20COVID19_Arg_May20_v2_text.csv')\n",
        "\n",
        "\n",
        "if load_from_google_drive:\n",
        "  # On google colab\n",
        "  # Mount GDrive and attach it to the colab for data I/O\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  # input_dir = '/content/drive/My Drive/covid19_argentina/data/input/'\n",
        "  output_dir = '/content/drive/My Drive/covid19_argentina/data/output/'\n",
        "  os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "else:\n",
        "  # If using jupyter-lab or jupyter notebook, load locally:\n",
        "  input_dir = './data/input/'\n",
        "  output_dir = './data/output/'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ecwFfsdEWXEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select subset of variables\n",
        "df = df[[\n",
        "    'PHQ9_Total',          # Puntuación total de depresión (PHQ-9)\n",
        "    'GAD7_Total',          # Puntuación total de ansiedad (GAD-7)\n",
        "    'Lockdown_adherence',  # Adherencia al confinamiento\n",
        "    'Age',                 # Edad\n",
        "    'Gender',              # Género\n",
        "    'Family_Income',       # Ingreso familiar\n",
        "    'Negat_thinking',      # Pensamiento negativo\n",
        "    'COGN_DIFFICULTIES_index',\n",
        "    'Mental_fatigue',\n",
        "    'Threat',\n",
        "    'Riskofcontagion',\n",
        "    'Lockdown_difficulty',\n",
        "    'Financialworry_present',\n",
        "    'Financialworry_future',\n",
        "    'Daily_stress_Index',\n",
        "    'IU_total',            # Intolerancia a la incertidumbre\n",
        "    'UCLA_LS_Total',       # Escala de soledad de UCLA\n",
        "]]\n",
        "df"
      ],
      "metadata": {
        "id": "g-9Uv0D8Ooj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dummy variable for categorical variable gender\n",
        "gender = pd.get_dummies(df['Gender'],prefix='Gender')\n",
        "gender = pd.get_dummies(gender,prefix='Gender')\n",
        "df = df.drop('Gender', axis=1)\n",
        "df['Gender_female'] = gender['Gender_1.0']\n",
        "# other genders were not included since there were only 9.\n",
        "variables = df.columns.values\n",
        "variables"
      ],
      "metadata": {
        "id": "gsnCcyDROovs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use cleaner names in the final table\n",
        "\n",
        "clean_names= dict(zip(\n",
        "    variables,\n",
        "    ['PHQ9', 'GAD7','Lockdown adherence','Age','Family income', 'Negative thinking','Cognitive troubles', 'Mental fatigue', 'Perceived threat', 'Perceived risk','Lockdown difficulty','Financial worries (present)','Financial worries (future)','Daily stress', 'Intolerance of uncertainty', 'Loneliness scale', 'Female', 'Male']\n",
        "\n",
        "    ))\n",
        "\n",
        "clean_names"
      ],
      "metadata": {
        "id": "ZKB6cDDpuc-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive statistics"
      ],
      "metadata": {
        "id": "OXJ9wUfNWyBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "HsyZQWrnDKEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observe the descriptive stats of the independent variables\n",
        "df.drop('PHQ9_Total',axis=1).describe()"
      ],
      "metadata": {
        "id": "4Ovwvy5GrYu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take a subsample of observations and variables for faster plotting"
      ],
      "metadata": {
        "id": "KkNTD5RjraQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subsample = 0.1 # 0.1=10% of data, 1 = 100%\n",
        "variables_to_plot = ['PHQ9_Total', 'GAD7_Total', 'Lockdown_adherence', 'Age','Family_Income'] # It\n",
        "df_subsample = df[variables_to_plot].sample(frac=subsample)\n",
        "sns.pairplot(df_subsample)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vM8nIJuSAkml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More thorough stats"
      ],
      "metadata": {
        "id": "fUwxt7J5Bnnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "\n",
        "def reg_coef(x,y,label=None,color=None, **kwargs):\n",
        "    \"\"\"Calcula y anota el coeficiente de correlación de Spearman y su significancia\"\"\"\n",
        "    ax = plt.gca()\n",
        "    r,p = spearmanr(x,y)\n",
        "    if p < 0.01:\n",
        "        sig_level = '***'\n",
        "    elif p < 0.05:\n",
        "        sig_level = '**'\n",
        "    elif p < 0.05:\n",
        "        sig_level = '*'\n",
        "    else:\n",
        "        sig_level = ''\n",
        "\n",
        "    ax.annotate('r = {:.2f} {}'.format(r, sig_level), xy=(0.5,0.5), xycoords='axes fraction', ha='center')\n",
        "    ax.texts[0].set_size(16)\n",
        "    ax.set_axis_off()\n",
        "\n",
        "# Create the plot\n",
        "g = sns.PairGrid(data=df_subsample, vars=df_subsample.columns, hue=None)\n",
        "g.map_upper(reg_coef)\n",
        "g = g.map_lower(sns.regplot, scatter_kws={\"edgecolor\": \"white\"})\n",
        "g = g.map_diag(sns.histplot, kde=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r8f96sq--noV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corrdot(*args, **kwargs):\n",
        "    corr_r = args[0].corr(args[1], 'spearman')\n",
        "    corr_text = f\"{corr_r:2.2f}\".replace(\"0.\", \".\")\n",
        "    ax = plt.gca()\n",
        "    ax.set_axis_off()\n",
        "    marker_size = abs(corr_r) * 10000\n",
        "    ax.scatter([.5], [.5], marker_size, [corr_r], alpha=0.75, cmap=\"coolwarm\",\n",
        "               vmin=-1, vmax=1, transform=ax.transAxes)\n",
        "    font_size = 40 #abs(corr_r) * 40 + 5\n",
        "    ax.annotate(corr_text, [.5, .5,],  xycoords=\"axes fraction\",\n",
        "                ha='center', va='center', fontsize=font_size)\n",
        "\n",
        "\n",
        "# Pairwise correlation plot\n",
        "sns.set(style='white', font_scale=1.6)\n",
        "# iris = sns.load_dataset('iris')\n",
        "g = sns.PairGrid(df_subsample, aspect=1.4, diag_sharey=False)\n",
        "g.map_lower(sns.regplot, lowess=True, ci=True, line_kws={'color': 'black'}, fit_reg=True,\n",
        "          x_jitter=.1, y_jitter=.1,\n",
        "            scatter_kws={\"s\": 1, \"alpha\":0.1}\n",
        "            )\n",
        "g.map_diag(sns.histplot, kde_kws={'color': 'black'})\n",
        "g.map_upper(corrdot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2k1mC-AbLJt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create DFs for each independent variable"
      ],
      "metadata": {
        "id": "R6c4iTKbCAvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA5eNnJqNi_p"
      },
      "outputs": [],
      "source": [
        "def add_top_column(df, top_col, inplace=True):\n",
        "    if not inplace:\n",
        "        df = df.copy()\n",
        "\n",
        "    df.columns = pd.MultiIndex.from_product([[top_col], df.columns])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH-oBUDVNi_1"
      },
      "outputs": [],
      "source": [
        "# Depression\n",
        "variables_depression = df.drop('PHQ9_Total',axis=1).columns.values\n",
        "X = df.drop('PHQ9_Total',axis=1).values\n",
        "feature_names = df.drop('PHQ9_Total',axis=1).columns\n",
        "feature_names = [clean_names.get(n) for n in feature_names]\n",
        "y = df['PHQ9_Total'].values\n",
        "print('depression independent variables', variables_depression)\n",
        "print(X.shape, y.shape)\n",
        "print('\\n\\n')\n",
        "\n",
        "# # Anxiety\n",
        "\n",
        "# variables_anxiety = df.drop('GAD7_Total',axis=1).columns.values\n",
        "# X_anxiety = df.drop('GAD7_Total',axis=1).values\n",
        "# y_anxiety = df['GAD7_Total'].values\n",
        "# print('Anxiety independent variables', variables_anxiety)\n",
        "# print(X_anxiety.shape, y_anxiety.shape)\n",
        "# print('\\n\\n')\n",
        "\n",
        "\n",
        "# # Lockdown Adherence\n",
        "\n",
        "# variables_lockdown = df.drop('Lockdown_adherence',axis=1).columns.values\n",
        "# X_lockdown = df.drop('Lockdown_adherence',axis=1).values\n",
        "# y_lockdown = df['Lockdown_adherence'].values\n",
        "# print('Lockdown Adherence independent variables', variables_lockdown)\n",
        "# print(X_lockdown.shape, y_lockdown.shape)\n",
        "# print('\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluation\n",
        "\n",
        "We're going to fit LASSO models and optimize the alpha or L1 parameter (regularization strength)."
      ],
      "metadata": {
        "id": "FM3YTxMACXHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple model\n"
      ],
      "metadata": {
        "id": "dC51dm85DUJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model_name_i = 'Lasso_80-20'\n",
        "\n",
        "# Held-out cross-validation 80-20 train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "model = Lasso()                # initializes model\n",
        "model.fit(X_train,y_train)                             # fit model\n",
        "intercept = model.intercept_                            # extract parameters\n",
        "print('Intercept: ', np.round(intercept,4))\n",
        "beta1 = model.coef_[0]                               # intercept and slopes same as in the .summary2() output above\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = metrics.r2_score(y_test,y_pred)\n",
        "print('Beta 1: ', np.round(beta1))\n",
        "rmse = metrics.mean_squared_error(y_test, y_pred, squared=False )\n",
        "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
        "r2 = metrics.r2_score(y_test, y_pred)\n",
        "round_to = 2\n",
        "results_dict = {\n",
        "    'y_train_min': np.min(y_train),\n",
        "    'y_train_max': np.max(y_train),\n",
        "    'RMSE':np.round(rmse,round_to ),\n",
        "    'MAE':np.round(mae,round_to ),\n",
        "    'R^2':np.round(r2,round_to ),\n",
        "    }\n",
        "results = pd.DataFrame(results_dict, index=[model_name_i]).round(3)\n",
        "results\n"
      ],
      "metadata": {
        "id": "ecU1cGzSDS21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot result for a regression task: true value vs predicted values\n",
        "# ============================================================\n",
        "plt.clf()\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.title(f\"RMSE: {np.round(rmse,round_to )}\\nMAE: {np.round(mae,round_to )}\\nR^2: {np.round(r2,round_to )}\")\n",
        "plt.xlabel('True values')\n",
        "plt.ylabel('Predicted values')\n",
        "plt.tight_layout()\n",
        "# plt.savefig(f'results_{ts}/scatter_{model_name_i}_{ts}.png', dpi=150)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "43V21rzUGPLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefs = list(model.coef_)                     # Obtain coefficients from GridSearch\n",
        "coefs= pd.DataFrame(coefs,index=feature_names, columns = ['Coef.']) # make DF\n",
        "coefs['Abs. Coef.'] = coefs['Coef.'].abs()  # add column with absolute values to sort by, both positive and negative values are important.\n",
        "coefs= coefs.sort_values('Abs. Coef.', ascending=False).reset_index() # sort by abs value and reset index to add a feature name column\n",
        "coefs= coefs.drop(['Abs. Coef.'], axis=1)   # drop abs value, it's job is done\n",
        "coefs.index +=1                             # Importance for publication, start index with 1 , as in 1st, 2nd, 3rd\n",
        "coefs= coefs.reset_index()                  # turn index into column\n",
        "coefs.columns= ['Importance', 'Feature', 'Std. Coef.'] # Clean column names\n",
        "feature_importance = coefs.copy()\n",
        "feature_importance"
      ],
      "metadata": {
        "id": "_ZAjhi8THJRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### k-fold cross-validation"
      ],
      "metadata": {
        "id": "-kNvESbgHKQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "splits = 5\n",
        "kf = KFold(n_splits=splits, random_state=42, shuffle=True) # shuffle could be good if the data is ordered in same way (by ID, date) which could introduce bias.\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "y = np.array(y)                     # so I can index\n",
        "results_mae = {}\n",
        "results_r2 = {}\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train, y_train = X[train_index], y[train_index]\n",
        "    X_test, y_test = X[test_index], y[test_index]\n",
        "\n",
        "    model = Lasso()                # initializes model\n",
        "\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    model.fit(X_train_scaled,y_train)                             # fit model\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    rmse = metrics.mean_squared_error(y_test, y_pred, squared=False )\n",
        "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
        "    r2 = metrics.r2_score(y_test, y_pred)\n",
        "    round_to = 2\n",
        "    results_dict = {\n",
        "        f'MAE_{i}':np.round(mae,round_to ),\n",
        "        f'R^2_{i}':np.round(r2,round_to ),\n",
        "        }\n",
        "    results_mae[f'MAE_{i}']=mae\n",
        "    results_r2[f'R^2_{i}']=r2\n"
      ],
      "metadata": {
        "id": "OHtIcvbHFeSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_all = pd.DataFrame(results_r2, index = ['score'])\n",
        "r2_all['R^2'] = r2_all.mean(axis=1).round(3)\n",
        "display(r2_all)\n",
        "mae_all = pd.DataFrame(results_mae, index = ['score'])\n",
        "mae_all['MAE'] = mae_all.mean(axis=1).round(3)\n",
        "display(mae_all)\n"
      ],
      "metadata": {
        "id": "GdX_pJGXISwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter tuning on training set"
      ],
      "metadata": {
        "id": "fgvjZh_vuUTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (6,6)"
      ],
      "metadata": {
        "id": "cMs0tQaM_-Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkcH7R5zNi_2"
      },
      "outputs": [],
      "source": [
        "# Train and test\n",
        "model_name_i = 'Lasso_80-20_tuned'\n",
        "\n",
        "#80-20 Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "alphas= np.logspace(-4, 0, 30) #equally spaced on log scale from 10**-4 (0.0004) to 10**0 (1)\n",
        "\n",
        "# Pipeline: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
        "pipe = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', Lasso())\n",
        "])\n",
        "\n",
        "# hyperparameters and their values we're testing through gridsearch\n",
        "param_grid = {\n",
        "    'model__alpha': alphas,\n",
        "}\n",
        "\n",
        "# Do hyperparameter tuning within the training set, using 5-fold CV\n",
        "search = GridSearchCV(pipe,param_grid, cv=5,n_jobs=-1) # perfrom k-fold CV on the training set\n",
        "\n",
        "search.fit(X_train,y_train) # Train model\n",
        "best_alpha = search.best_params_['model__alpha']\n",
        "print('Best alpha: ', best_alpha)\n",
        "# now use the best value to train the final model\n",
        "\n",
        "# Train final model\n",
        "pipe = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', Lasso(alpha = best_alpha))\n",
        "])\n",
        "pipe.fit(X_train,y_train) # train\n",
        "\n",
        "# Test\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "r2 = metrics.r2_score(y_test,y_pred)\n",
        "print('Beta 1: ', np.round(beta1))\n",
        "rmse = metrics.mean_squared_error(y_test, y_pred, squared=False )\n",
        "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
        "r2 = metrics.r2_score(y_test, y_pred)\n",
        "round_to = 2\n",
        "results_dict = {\n",
        "    'y_train_min': np.min(y_train),\n",
        "    'y_train_max': np.max(y_train),\n",
        "    'RMSE':np.round(rmse,round_to ),\n",
        "    'MAE':np.round(mae,round_to ),\n",
        "    'R^2':np.round(r2,round_to ),\n",
        "    }\n",
        "results = pd.DataFrame(results_dict, index=[model_name_i]).round(3)\n",
        "display(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot result for a regression task: true value vs predicted values\n",
        "# ============================================================\n",
        "plt.clf()\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.title(f\"RMSE: {np.round(rmse,round_to )}\\nMAE: {np.round(mae,round_to )}\\nR^2: {np.round(r2,round_to )}\"\n",
        "        )\n",
        "plt.xlabel('True values')\n",
        "plt.ylabel('Predicted values')\n",
        "plt.tight_layout()\n",
        "# plt.savefig(f'results_{ts}/scatter_{model_name_i}_{ts}.png', dpi=150)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EKqTjlvsL1hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKgOIZiiNi_2"
      },
      "outputs": [],
      "source": [
        "coefs = list(model.coef_)                     # Obtain coefficients from GridSearch\n",
        "coefs= pd.DataFrame(coefs,index=feature_names, columns = ['Coef.']) # make DF\n",
        "coefs['Abs. Coef.'] = coefs['Coef.'].abs()  # add column with absolute values to sort by, both positive and negative values are important.\n",
        "coefs= coefs.sort_values('Abs. Coef.', ascending=False).reset_index() # sort by abs value and reset index to add a feature name column\n",
        "coefs= coefs.drop(['Abs. Coef.'], axis=1)   # drop abs value, it's job is done\n",
        "coefs.index +=1                             # Importance for publication, start index with 1 , as in 1st, 2nd, 3rd\n",
        "coefs= coefs.reset_index()                  # turn index into column\n",
        "coefs.columns= ['Importance', 'Feature', 'Std. Coef.'] # Clean column names\n",
        "feature_importance = coefs.copy()\n",
        "feature_importance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "gjwCPWPfEH5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (4,4)"
      ],
      "metadata": {
        "id": "e1o62v2ZFYn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from matplotlib.pyplot import figure\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "WX6gkGsVJabk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(4,4))\n",
        "plt.hist(y)\n",
        "plt.xlabel('PHQ9')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HS5HhQe6EI2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_depression_binary = []\n",
        "for i in y:\n",
        "  if i >= 10:\n",
        "    y_depression_binary.append(1)\n",
        "  else:\n",
        "    y_depression_binary.append(0)\n",
        "\n",
        "y_depression_binary = np.array(y_depression_binary)\n",
        "plt.hist(y_depression_binary)\n",
        "plt.xticks(ticks = [0,1], labels = ['Not depressed', 'Depressed'])\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6LDxqDIREOKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(y_depression_binary) # Desbalanceado"
      ],
      "metadata": {
        "id": "seLoHELRHq5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(alphas,3)"
      ],
      "metadata": {
        "id": "uLRShzwKPZ61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_grid = [\n",
        "              {\n",
        "                'estimator':[LogisticRegression(class_weight='balanced', penalty = 'l1')],\n",
        "                'estimator__C': [0.1, 0.3, 0.6, 0.9],\n",
        "                },\n",
        "                {\n",
        "                'estimator':[SVC(class_weight='balanced',probability=True)],\n",
        "                'estimator__C': [0.1, 1, 10],\n",
        "                 'estimator__kernel': ['linear', 'rbf'],\n",
        "                },\n",
        "               # For the ROC AUC below, we need to output the probabilities\n",
        "                # {\n",
        "                # 'estimator': [RandomForestClassifier()],\n",
        "                # 'estimator__n_estimators': [50, 250],\n",
        "                # 'estimator__max_depth': [3,10],\n",
        "                # },\n",
        "               ]"
      ],
      "metadata": {
        "id": "AAfkQrHrJ13P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "toy = False\n",
        "\n",
        "if toy:\n",
        "  # use a subsample\n",
        "  m = 1000\n",
        "  X_toy, y_depression_binary_toy = zip(*random.sample(list(zip(X, y_depression_binary)), m))\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_toy, y_depression_binary_toy, test_size=0.2, random_state=42)\n",
        "else:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y_depression_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('normalize', StandardScaler()),\n",
        "    ('estimator', LogisticRegression(class_weight='balanced'))\n",
        "    ])#initialize with any classifier, but then it will test all estimators specified in params_grid\n",
        "\n",
        "# Train the grid search model, use refit, to refit the best params, scoring is what you want to optimize\n",
        "gs = GridSearchCV(pipeline, params_grid, cv=5, n_jobs=-1, scoring='f1', refit=True).fit(X_train, y_train) # I use f1-score because it is less affected by class imbalance\n",
        "# Best performing model and its corresponding hyperparameters\n",
        "print('=====')\n",
        "print('best parameters', gs.best_params_)\n",
        "print('=====')\n",
        "\n",
        "# Test data performance\n",
        "y_proba = gs.predict_proba(X_test)       # Get predicted probabilities\n",
        "y_proba = np.round(y_proba,2)               # round to 2 decimals\n",
        "y_proba                                     # probabilitiesfor y=0 and y=1\n",
        "y_proba_1 = y_proba[:,1]\n",
        "y_pred = np.argmax(y_proba, axis=1) # in binary classification, threshold 0.5\n",
        "\n",
        "print(classification_report(y_pred, y_test))\n",
        "cm = confusion_matrix(y_test, y_pred, )\n",
        "\n",
        "cm_display = ConfusionMatrixDisplay(cm, display_labels = ['Healthy', 'Depressed']).plot()\n",
        "plt.grid(False)\n"
      ],
      "metadata": {
        "id": "UHoPIAqHLNpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Custom classification report\n",
        "precision = metrics.precision_score(y_test, y_pred)\n",
        "recall = metrics.recall_score(y_test, y_pred)\n",
        "specificity = metrics.recall_score(y_test, y_pred, pos_label=0)    # specificity is the recall of the negative class or control group\n",
        "f1 = metrics.f1_score(y_test, y_pred)\n",
        "roc_auc = metrics.roc_auc_score(y_test, y_proba_1)  # IMPORTANT: other metrics take binary predictions y_pred. Here we test different thresholds, so we need probabilities (this will change the ROC AUC score)\n",
        "\n",
        "results_dict = {\n",
        "    'Precision':precision,\n",
        "    'Recall':recall,\n",
        "    'Specificity':specificity,\n",
        "    'F1':f1,\n",
        "    'ROC AUC':roc_auc,\n",
        "    }\n",
        "\n",
        "results = pd.DataFrame(results_dict, index=['model']).round(3)\n",
        "results['best_params'] =  str(gs.best_params_)\n",
        "results"
      ],
      "metadata": {
        "id": "K07R64lLNOhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification permutation import"
      ],
      "metadata": {
        "id": "l6H2solnvPsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://scikit-learn.org/1.5/modules/permutation_importance.html\n",
        "\n",
        "result = permutation_importance(gs, X_test, y_test, n_repeats=10,\n",
        "                                random_state=42, n_jobs=-1)\n",
        "figure(figsize=(12,8), dpi=300)\n",
        "sorted_idx = result.importances_mean.argsort()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(12,8)\n",
        "ax.boxplot(result.importances[sorted_idx].T,\n",
        "           vert=False, labels=variables_depression[sorted_idx])\n",
        "ax.set_title(\"Permutation Importances (test set)\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PgNYcDbyR1sa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}